{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "HWIImv-32rlP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "36nPRnj60xdk"
   },
   "outputs": [],
   "source": [
    "filename = \"Raw Data/touchevent.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoupling_time(r):\n",
    "    '''\n",
    "    This will output in this format: 1970-08-22 19:25:00 \n",
    "    '''\n",
    "    s = str(r)\n",
    "    year, month, day, hour, minute, second = s[:4], s[4:6], s[6:8], s[8:10], s[10:12], s[12:14]\n",
    "    \n",
    "    return '-'.join([year, month, day]) + ' ' + ':'.join([hour, minute, second])\n",
    "#decoupling_time(20201117235750093)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "-gBp1VMc1s7f",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1584it [00:59, 25.49it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "2337it [01:29, 23.98it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "3318it [02:11, 24.00it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "4116it [02:46, 22.04it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "5489it [03:51, 20.34it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "5999it [04:16, 21.63it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "6238it [04:27, 19.23it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "6775it [04:56, 15.59it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "7987it [06:00, 21.11it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "8692it [06:39, 20.01it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "8968it [06:55, 14.63it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "9324it [07:15, 18.56it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "10057it [07:54, 18.12it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "10591it [08:23, 19.27it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "10677it [08:28, 16.51it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "12650it [10:26, 11.83it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "12848it [10:40, 14.30it/s]/tmp/ipykernel_45258/3962094761.py:11: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
      "12922it [10:45, 20.02it/s]\n"
     ]
    }
   ],
   "source": [
    "final_data = pd.DataFrame()\n",
    "\n",
    "row_count = 10000\n",
    "c = 0\n",
    "for chunk in tqdm(pd.read_csv(filename, chunksize=row_count)): \n",
    "    #deep copy \n",
    "    temp = pd.DataFrame(columns=['experimentid', 'userid'])\n",
    "    temp = chunk[['experimentid', 'userid']]\n",
    "    \n",
    "    #turning now time from raw to machine readable ; #every minute has a specific count                                         \n",
    "    shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
    "        decoupling_time), yearfirst=True).dt.floor('min')\n",
    "    temp.insert(2, 'timestamp', shortened_times)\n",
    "    #attenzione: il conteggio potrebbe essere meglio rappresentato\n",
    "    # da una misura di massimo un numero di tocchi al secondo, oltre \n",
    "    #la quale si è outliers o c'è un errore nei dati; quando viene \n",
    "    # portato al minuto, la somma può essere divisa per secondi (60)\n",
    "    \n",
    "    #grouping \n",
    "    df_grouped = temp.groupby(['userid', 'experimentid', 'timestamp']).size()                                         \n",
    "    df_grouped = df_grouped.reset_index(name='touches')\n",
    "    \n",
    "    #appending to a global df\n",
    "    final_data = pd.concat([final_data, df_grouped], ignore_index=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data.to_csv('reduced_file.csv', index=False)\n",
    "second_grouping = final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoupling_time2(r):\n",
    "    '''\n",
    "    This will output in this format: 1970-08-22 19:25:00 \n",
    "    '''\n",
    "    s = str(r)\n",
    "    year, month, day, hour, minute, second = s[:4], s[5:7], s[8:10], s[-8:-6], s[-5:-3], s[-2:]\n",
    "    \n",
    "    return '-'.join([year, month, day]) + ' ' + ':'.join([hour, minute, second])\n",
    "#decoupling_time('2020-11-27 15:04:00')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doing it again but on the whole dataset to avoid duplicates of rows.\n",
    "\n",
    "filename = 'touch_sensor_Fluve2.csv'\n",
    "chunk = pd.read_csv(filename)\n",
    "temp = pd.DataFrame(columns=['experimentid', 'userid'])\n",
    "temp = chunk[['experimentid', 'userid']]\n",
    "    \n",
    "    #turning now time from raw to machine readable ; #every minute has a specific count                                         \n",
    "shortened_times = pd.to_datetime(chunk['timestamp'].apply(\n",
    "decoupling_time2), yearfirst=True).dt.floor('min')\n",
    "temp.insert(2, 'timestamp', shortened_times)\n",
    "#attenzione: il conteggio potrebbe essere meglio rappresentato\n",
    "# da una misura di massimo un numero di tocchi al secondo, oltre \n",
    "#la quale si è outliers o c'è un errore nei dati; quando viene \n",
    "# portato al minuto, la somma può essere divisa per secondi (60)\n",
    "    \n",
    "#grouping \n",
    "df_grouped = temp.groupby(['userid', 'experimentid', 'timestamp']).size()                                         \n",
    "df_grouped = df_grouped.reset_index(name='touches')\n",
    "    \n",
    "    #appending to a global df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1235536, 4) We're done!\n"
     ]
    }
   ],
   "source": [
    "print(df_grouped.shape, \"We're done!\")  #Now the rows are only 1235536; \n",
    "                                        #Run again the cell above to prove that there are no more time duplicates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.to_csv('touch_sensor_Fluve2.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
